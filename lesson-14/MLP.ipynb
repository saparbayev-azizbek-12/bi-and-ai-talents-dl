{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saparbayev-azizbek-12/bi-and-ai-talents-dl/blob/main/lesson-14/MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Homework"
      ],
      "metadata": {
        "id": "kG_-W6rnXbPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!wget https://raw.githubusercontent.com/karpathy/makemore/refs/heads/master/names.txt"
      ],
      "metadata": {
        "id": "IwL1kf4DXaUv"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "names = open('names.txt').read().splitlines()\n",
        "vocab = sorted(set(''.join(names) + '.'))\n",
        "stoi = {v: i for i, v in enumerate(vocab)}\n",
        "itos = {i: v for v, i in stoi.items()}\n",
        "\n",
        "def encode(name: str) -> list[int]:\n",
        "    return [stoi[s] for s in name]\n",
        "\n",
        "def decode(seq: list[int]) -> str:\n",
        "    return ''.join([itos[i] for i in seq])"
      ],
      "metadata": {
        "id": "kOtkbWN7VXZ3"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "8WxBTkGscwzb"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 3\n",
        "X, Y = [], []\n",
        "\n",
        "for name in names:\n",
        "    context = [0] * block_size\n",
        "    for ch in name + '.':\n",
        "        ix = stoi[ch]\n",
        "        X.append(context)\n",
        "        Y.append(ix)\n",
        "        context = context[1:] + [ix]\n",
        "\n",
        "X = torch.tensor(X, device=device)\n",
        "Y = torch.tensor(Y, device=device)"
      ],
      "metadata": {
        "id": "vfLmsoczVcGi"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLRhwMBznrD8",
        "outputId": "e797fbd6-fa7f-47c0-cc18-a3b0390e3daf"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([228146, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_percent = 0.7\n",
        "val_percent = 0.15\n",
        "total_samples = X.size()[0]\n",
        "train_size = int(total_samples * train_percent)\n",
        "val_size = int(total_samples * val_percent)\n",
        "\n",
        "Xtr, Ytr = X[:train_size], Y[:train_size]\n",
        "Xval, Yval = X[train_size : train_size + val_size], Y[train_size : train_size + val_size]\n",
        "Xts, Yts = X[train_size + val_size :], Y[train_size + val_size :]"
      ],
      "metadata": {
        "id": "5PpIRUprkwYi"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(model, X, Y):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model.forward(X)\n",
        "        pred = torch.argmax(logits, dim=1)\n",
        "        acc = (pred == Y).float().mean().item()\n",
        "    return acc"
      ],
      "metadata": {
        "id": "yXdJ6Naqq2KU"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self, vocab_size, n_embd=10, n_hidden=100, block_size=3, scale=0.1, device='cuda', lr=0.05, p=0.2):\n",
        "        super().__init__()\n",
        "        torch.manual_seed(42)\n",
        "        self.block_size = block_size\n",
        "        self.C = torch.nn.Parameter(torch.randn(vocab_size, n_embd) * scale)\n",
        "        self.W1 = torch.nn.Parameter(torch.randn(block_size * n_embd, n_hidden) * scale)\n",
        "        self.b1 = torch.nn.Parameter(torch.zeros(n_hidden))\n",
        "        self.W2 = torch.nn.Parameter(torch.randn(n_hidden, vocab_size) * scale)\n",
        "        self.b2 = torch.nn.Parameter(torch.zeros(vocab_size))\n",
        "        self.W3 = torch.nn.Parameter(torch.randn(block_size * n_embd, vocab_size) * scale)\n",
        "        self.dropout = torch.nn.Dropout(p=p)\n",
        "        self.optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
        "        self.to(device)\n",
        "        self.history = []\n",
        "\n",
        "    def forward(self, X):\n",
        "        xenc = self.C[X]\n",
        "        x_emb = xenc.view(xenc.size(0), -1)\n",
        "        h = torch.tanh(x_emb @ self.W1 + self.b1)\n",
        "        h_drop = self.dropout(h)\n",
        "        logits = h_drop @ self.W2 + self.b2 + x_emb @ self.W3\n",
        "        return logits\n",
        "\n",
        "    def loss(self, X, Y):\n",
        "        logits = self.forward(X)\n",
        "        return F.cross_entropy(logits, Y)\n",
        "\n",
        "    def params(self):\n",
        "      print(self.state_dict().keys())\n",
        "\n",
        "    def fit(self, Xtr, Ytr, Xval, Yval, max_steps=201, patience=5):\n",
        "      super().train()\n",
        "      best_test_acc = 0\n",
        "      patience_counter = 0\n",
        "      self.history = []\n",
        "\n",
        "      for step in range(max_steps):\n",
        "          self.optimizer.zero_grad()\n",
        "          loss = self.loss(Xtr, Ytr)\n",
        "          loss.backward()\n",
        "          self.optimizer.step()\n",
        "          train_acc = accuracy(self, Xtr, Ytr)\n",
        "          test_acc = accuracy(self, Xval, Yval)\n",
        "          self.history.append({'step': step, 'loss': loss.item(), 'train_acc': train_acc, 'test_acc': test_acc}) # Store history\n",
        "          if step % 20 == 0:\n",
        "              print(f\"Step {step:3d} | Loss: {loss.item():.4f} | Train Acc: {train_acc:.3f} | Test Acc: {test_acc:.3f}\")\n",
        "\n",
        "          if test_acc > best_test_acc:\n",
        "              best_test_acc = test_acc\n",
        "              patience_counter = 0\n",
        "              best_state = {k: v.clone() for k, v in self.state_dict().items()}\n",
        "          else:\n",
        "              patience_counter += 1\n",
        "\n",
        "          if patience_counter >= patience:\n",
        "              print(f\"\\nEarly stopping. Best Test Accuracy: {best_test_acc:.3f}\")\n",
        "              self.load_state_dict(best_state)\n",
        "              break\n",
        "\n",
        "    def get_history(self):\n",
        "        return self.history\n",
        "\n",
        "    def generate(self, num_samples=5):\n",
        "        super().eval()\n",
        "        for _ in range(num_samples):\n",
        "            out = []\n",
        "            context = [0] * self.block_size\n",
        "            while True:\n",
        "                x = torch.tensor([context], device=device)\n",
        "                logits = self.forward(x)\n",
        "                probs = F.softmax(logits, dim=1)\n",
        "                ix = torch.multinomial(probs, num_samples=1).item()\n",
        "                if itos[ix] == '.':\n",
        "                    break\n",
        "                out.append(itos[ix])\n",
        "                context = context[1:] + [ix]\n",
        "            print(''.join(out))"
      ],
      "metadata": {
        "id": "nJM0yau8MZYX"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab)\n",
        "model = MLP(vocab_size)"
      ],
      "metadata": {
        "id": "PY2RrFg4gToF"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.generate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDqNloKFgajI",
        "outputId": "7face153-d703-4a67-a806-c282ad05f6fc"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "v\n",
            "itajokyvgrzppeopkgbr\n",
            "eqlskmairiphqiojfibjxqsvf\n",
            "btuupwpoqxgzmiirwxiybqoionyuqucicpmoph\n",
            "i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(Xtr, Ytr, Xval, Yval, patience=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZ4aZUEagfin",
        "outputId": "bd917427-1782-49a4-8a50-47a78119a219"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step   0 | Loss: 3.3015 | Train Acc: 0.174 | Test Acc: 0.134\n",
            "Step  20 | Loss: 2.3140 | Train Acc: 0.280 | Test Acc: 0.240\n",
            "Step  40 | Loss: 2.2446 | Train Acc: 0.293 | Test Acc: 0.244\n",
            "Step  60 | Loss: 2.2094 | Train Acc: 0.304 | Test Acc: 0.249\n",
            "Step  80 | Loss: 2.1684 | Train Acc: 0.315 | Test Acc: 0.254\n",
            "Step 100 | Loss: 2.1345 | Train Acc: 0.323 | Test Acc: 0.250\n",
            "Step 120 | Loss: 2.0965 | Train Acc: 0.337 | Test Acc: 0.262\n",
            "Step 140 | Loss: 2.0708 | Train Acc: 0.344 | Test Acc: 0.264\n",
            "Step 160 | Loss: 2.0521 | Train Acc: 0.348 | Test Acc: 0.275\n",
            "Step 180 | Loss: 2.0341 | Train Acc: 0.354 | Test Acc: 0.277\n",
            "Step 200 | Loss: 2.0273 | Train Acc: 0.356 | Test Acc: 0.277\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.generate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xrsbc6Grgv7t",
        "outputId": "4d24147e-ccc2-4e3d-9c6e-253adf43944d"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "caeli\n",
            "crelia\n",
            "nakiyah\n",
            "ariah\n",
            "liley\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(Xtr, Ytr, Xval, Yval, patience=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XaFhmPYhHXX",
        "outputId": "8b26bd44-0db0-4986-b5d7-592294982427"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step   0 | Loss: 2.6009 | Train Acc: 0.343 | Test Acc: 0.275\n",
            "Step  20 | Loss: 2.0297 | Train Acc: 0.355 | Test Acc: 0.276\n",
            "Step  40 | Loss: 2.0109 | Train Acc: 0.360 | Test Acc: 0.280\n",
            "Step  60 | Loss: 2.0031 | Train Acc: 0.361 | Test Acc: 0.282\n",
            "Step  80 | Loss: 1.9980 | Train Acc: 0.363 | Test Acc: 0.281\n",
            "Step 100 | Loss: 2.0029 | Train Acc: 0.361 | Test Acc: 0.283\n",
            "\n",
            "Early stopping. Best Test Accuracy: 0.287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.generate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfzlM0s1hK1l",
        "outputId": "c1d074d8-62c6-49ce-aea1-231ea893b808"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pianne\n",
            "iti\n",
            "warli\n",
            "shandreigh\n",
            "jayla\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(Xtr, Ytr, Xval, Yval, patience=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAf0-I06hPqm",
        "outputId": "75d9b513-d408-40b4-e5e9-2eedef198c3b"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step   0 | Loss: 2.6413 | Train Acc: 0.336 | Test Acc: 0.247\n",
            "Step  20 | Loss: 2.0083 | Train Acc: 0.361 | Test Acc: 0.279\n",
            "\n",
            "Early stopping. Best Test Accuracy: 0.284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.generate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOFSKoQChRz4",
        "outputId": "deb78dfc-9600-480c-96ec-b57b2137bd03"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maddisia\n",
            "lorin\n",
            "jenner\n",
            "shneannooris\n",
            "jermelan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"model.pkl\")"
      ],
      "metadata": {
        "id": "ZvSMlHLS0Arh"
      },
      "execution_count": 198,
      "outputs": []
    }
  ]
}