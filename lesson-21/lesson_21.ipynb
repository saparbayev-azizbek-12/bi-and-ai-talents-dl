{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMc8TQNrU1J1z2C0RxWIqzP"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "V0_9jZstNvTJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75ead35b-b2ff-4c38-ea17-e0e3bb5f642e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/dl_course/lesson-21/data/smile-annotations-final.csv\"\n",
        "df = pd.read_csv(file_path, header=None)"
      ],
      "metadata": {
        "id": "r3zfY4V3PWgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = [\"id\", \"text\", \"label\"]"
      ],
      "metadata": {
        "id": "zD1noH1hRlfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].drop_duplicates()\n",
        "rm_values = [\"nocode\", \"not-relevant\", \"disgust|angry\", \"happy|surprise\", \"happy|sad\", \"sad|disgust\", \"sad|angry\", \"sad|disgust|angry\"]\n",
        "df = df[~df['label'].isin(rm_values)]\n",
        "df['label'].value_counts()"
      ],
      "metadata": {
        "id": "YqmM7EL2U-Ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = list(df[\"label\"].drop_duplicates())\n",
        "itos = {i:v for i,v in enumerate(labels)}\n",
        "stoi = {v:i for i,v in itos.items()}\n",
        "stoi"
      ],
      "metadata": {
        "id": "3mPojIGhkMfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['text'].to_list()\n",
        "Y = df[\"label\"].apply(lambda row: stoi[row]).values"
      ],
      "metadata": {
        "id": "K2px9fgApUDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Xtr, Xtemp, Ytr, Ytemp = train_test_split(\n",
        "    X, Y,\n",
        "    train_size=0.7,\n",
        "    stratify=Y,\n",
        "    shuffle=True,\n",
        "    random_state=42\n",
        "  )\n",
        "\n",
        "Xval, Xts, Yval, Yts = train_test_split(\n",
        "    Xtemp, Ytemp,\n",
        "    train_size=0.5,\n",
        "    stratify=Ytemp,\n",
        "    shuffle=True,\n",
        "    random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "FGLQpm3PmXXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "def tokenize(texts):\n",
        "  return tokenizer(\n",
        "      texts,\n",
        "      padding=True,\n",
        "      truncation=True,\n",
        "      max_length=128,\n",
        "      return_tensors='pt'\n",
        "  )\n",
        "\n",
        "Xtr_tokenized = tokenize(Xtr)\n",
        "Xval_tokenized = tokenize(Xval)\n",
        "Xts_tokenized = tokenize(Xts)"
      ],
      "metadata": {
        "id": "J6VLCVSwg-1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtr_tokenized['input_ids'][0]"
      ],
      "metadata": {
        "id": "8feCh6zkGaGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, X, Y):\n",
        "    super().__init__()\n",
        "    self.X = X\n",
        "    self.Y = Y\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.X['input_ids'])\n",
        "\n",
        "  def __getitem__(self, id):\n",
        "    message = {k: v[id] for k, v in self.X.items()}\n",
        "    label = torch.tensor(self.Y[id])\n",
        "    return message, label\n",
        "\n",
        "Dtr = CustomDataset(Xtr_tokenized, Ytr)\n",
        "Dval = CustomDataset(Xval_tokenized, Yval)\n",
        "Dts = CustomDataset(Xts_tokenized, Yts)"
      ],
      "metadata": {
        "id": "Mri0HnE1lgke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Dtr[0]"
      ],
      "metadata": {
        "id": "zC7_XucQKzxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DLtr = DataLoader(Dtr, batch_size=32, shuffle=True)\n",
        "DLval = DataLoader(Dval, batch_size=32, shuffle=True)\n",
        "DLts = DataLoader(Dts, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "m6H2GczfJboU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"google-bert/bert-base-uncased\",\n",
        "    num_labels=len(labels)\n",
        ")"
      ],
      "metadata": {
        "id": "0DMbp5oOHKC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "6Oh75jmYMWLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=0.03)"
      ],
      "metadata": {
        "id": "LA24Nw0HMvI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, dataloader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for inputs, labels in dataloader:\n",
        "\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(**inputs, labels=labels)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n"
      ],
      "metadata": {
        "id": "FL0k0FsLM2Xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_epoch(model, dataloader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(**inputs, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            logits = outputs.logits\n",
        "\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    acc = correct / total\n",
        "    return total_loss / len(dataloader), acc\n"
      ],
      "metadata": {
        "id": "1MGjzhSYM5cu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 3\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss = train_epoch(model, DLtr)\n",
        "    val_loss, val_acc = eval_epoch(model, DLval)\n",
        "\n",
        "    print(f\"\"\"\n",
        "    Epoch {epoch+1}\n",
        "    Train loss: {train_loss:.4f}\n",
        "    Val loss:   {val_loss:.4f}\n",
        "    Val acc:    {val_acc:.4f}\n",
        "    \"\"\")\n"
      ],
      "metadata": {
        "id": "6oPkid2FM8bH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}